{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "# Initialize the LLM (here we use OpenAI’s model)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "        \n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"What are Distillation in Machine Learning and How does it Affect the Financial Markers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://machine-learning-made-simple.medium.com/deepseek-r1-model-distillation-and-how-da-ai-models-markets-will-be-impacted-5f576c4ad52c',\n",
       "  'content': 'If anyone can replicate models, what builds loyalty? Especially given the performance of distillation- which lets smaller models copy more'},\n",
       " {'url': 'https://labelbox.com/blog/a-pragmatic-introduction-to-model-distillation-for-ai-developers/',\n",
       "  'content': 'The distillation process involves training the smaller neural network (the student) to mimic the behavior of the larger, more complex teacher'},\n",
       " {'url': 'https://cidl.csd.auth.gr/resources/conference_pdfs/Online%20Knowledge%20Distillation%20for%20Financial%20Timeseries%20Forecasting_INISTA2022.pdf',\n",
       "  'content': 'Recent findings in the literature have already highlighted the positive effect of using knowledge distillation approaches for training trading agents using deep'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import json\n",
    "import re\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\",temperature=0.5)\n",
    "\n",
    "class State(MessagesState):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Imports (adjust to your environment)\n",
    "#############################################\n",
    "# from your_library import SystemMessage, HumanMessage, AIMessage, MessagesState\n",
    "# from your_library import StateGraph, MemorySaver, START, END\n",
    "# from your_library import GraphOutput\n",
    "# model = ...  # Some object with .invoke(messages) to get an AI response\n",
    "\n",
    "#############################################\n",
    "# System Message Setup\n",
    "#############################################\n",
    "content = \"\"\"ChatGPT, I would like to request your assistance in creating an AI-powered prompt rewriter, which can help me rewrite and refine prompts that I intend to use with you, ChatGPT, for the purpose of obtaining improved responses. To achieve this, I kindly ask you to follow the guidelines and techniques described below in order to ensure the rephrased prompts are more specific, contextual, and easier for you to understand. Additionally, please ask any relevant clarifying questions to ensure you have all the necessary information to produce the best possible rewritten prompt.\n",
    "\n",
    "Identify the main subject and objective\n",
    "Examine the original prompt and identify its primary subject and intended goal. Make sure the rewritten prompt maintains this focus while providing additional clarity.\n",
    "\n",
    "Ask clarifying questions (when necessary)\n",
    "If you find any part of the original prompt unclear, ambiguous, or lacking relevant context, ask specific, open-ended clarifying questions to gather more information. Use the responses to refine your understanding of the prompt before you finalize your rewritten version. The questions should have 4 possible answer choices.\n",
    "\n",
    "Add context\n",
    "Enhance the original prompt with relevant background information, historical context, or specific examples, making it easier to comprehend the subject matter and provide more accurate responses.\n",
    "\n",
    "Ensure specificity\n",
    "Rewrite the prompt in a way that narrows down the topic or question, so it becomes more precise and targeted. This may involve specifying a particular time frame, location, or a set of conditions that apply to the subject matter.\n",
    "\n",
    "Use clear and concise language\n",
    "Make sure the rewritten prompt uses simple, unambiguous language to convey the message, avoiding jargon or overly complex vocabulary. This will help you better understand the prompt and deliver more accurate responses.\n",
    "\n",
    "Incorporate open-ended questions\n",
    "If the original prompt contains a yes/no question or a query that may lead to a limited response, consider rephrasing it into an open-ended question that encourages a more comprehensive and informative answer.\n",
    "\n",
    "Avoid leading questions\n",
    "Ensure that the rewritten prompt does not contain any biases or assumptions that may influence your response. Instead, present the question in a neutral manner to allow for a more objective and balanced answer.\n",
    "\n",
    "Provide instructions when necessary\n",
    "If the desired output requires a specific format, style, or structure, include clear and concise instructions within the rewritten prompt to guide you in generating the response accordingly.\n",
    "\n",
    "Ensure the prompt length is appropriate\n",
    "While rewriting, make sure the prompt is neither too short nor too long. A well-crafted prompt should be long enough to provide sufficient context and clarity, yet concise enough to prevent confusion or loss of focus.\n",
    "\n",
    "With these guidelines in mind, I would like you to transform yourself into a “prompt rewriter,” capable of refining and enhancing any given prompt to ensure it elicits the most accurate, relevant, and comprehensive responses when used with ChatGPT.\n",
    "\n",
    "Please begin by examining the original prompt.\n",
    "If you need more information, ask clarifying questions.\n",
    "Once all ambiguities are resolved, provide your rewritten version of the prompt based on the instructions above.\n",
    "\"\"\"\n",
    "\n",
    "sys_msg = SystemMessage(\n",
    "    content=content\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#############################################\n",
    "# Node Functions\n",
    "#############################################\n",
    "\n",
    "def generate_questions(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Generates exactly three questions about the user's topic.\n",
    "    Expects the last user message to contain the topic.\n",
    "    \"\"\"\n",
    "    # The user topic is the last message content from the user:\n",
    "    topic = state[\"messages\"][-1].content  # e.g., \"the user wants to learn about X\"\n",
    "\n",
    "    prompt = f\"\"\"Ask the clarifying questions on the following topic: {topic}\n",
    "    Please return exactly three clarifying questions about this topic \n",
    "    in the following JSON format (and no additional text):\n",
    "    {{\n",
    "        \"question1\": \"Your first question here\",\n",
    "        \"question2\": \"Your second question here\",\n",
    "        \"question3\": \"Your third question here\"\n",
    "    }}\n",
    "    Ensure your output is valid JSON and do not include any extra keys or text.\n",
    "    \"\"\"\n",
    "    # Ask the model to generate 3 questions\n",
    "    generated_questions = model.invoke([\n",
    "        sys_msg, \n",
    "        AIMessage(content=prompt)\n",
    "    ])\n",
    "\n",
    "    pattern1 = r'\"question1\":\\s*\"([^\"]+)\"'\n",
    "    pattern2 = r'\"question2\":\\s*\"([^\"]+)\"'\n",
    "    pattern3 = r'\"question3\":\\s*\"([^\"]+)\"'\n",
    "    match = re.search(pattern1, generated_questions.content)\n",
    "    match2 = re.search(pattern2, generated_questions.content)\n",
    "    match3 = re.search(pattern3, generated_questions.content)\n",
    "    if match:\n",
    "        question = match.group(1)\n",
    "        q1 = question\n",
    "\n",
    "    if match2:\n",
    "        question = match2.group(1)\n",
    "        q2 = question\n",
    "\n",
    "    if match3:\n",
    "        question = match3.group(1)\n",
    "        q3 = question\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(content=f\"Question 1 related to {topic}: {q1}\"),\n",
    "            AIMessage(content=f\"Question 2 related to {topic}: {q2}\"),\n",
    "            AIMessage(content=f\"Question 3 related to {topic}: {q3}\")\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def human_feedback_answers(state: MessagesState):\n",
    "    \"\"\"\n",
    "    This node is triggered once the user has provided their answers.\n",
    "    In this example, the logic is minimal because we handle collecting\n",
    "    answers in the main Python loop. We simply pass through here.\n",
    "    \"\"\"\n",
    "    # Optionally, you can do more logic or store data in state[\"meta\"], etc.\n",
    "    return {}  # No new messages—just a placeholder.\n",
    "\n",
    "\n",
    "def create_prompt(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Create a final prompt or summary using the user’s two answers.\n",
    "    \"\"\"\n",
    "    # Collect the last two HumanMessages (the user answers).\n",
    "    # In many cases, you might find them by indexing or using a filter.\n",
    "    user_messages = [m for m in state[\"messages\"] if isinstance(m, HumanMessage)]\n",
    "    \n",
    "    # If you only store two answers, they should be the last two\n",
    "    answer1 = user_messages[-3].content\n",
    "    answer2 = user_messages[-2].content\n",
    "    answer3 = user_messages[-1].content\n",
    "    original_prompt = f\"\"\"  \n",
    "    I want to create a structured curriculum for learning {state[\"messages\"][0].content} from the ground up. Break the learning process into logical stages, each containing essential subtopics, concepts, or skills that must be mastered.\n",
    "\n",
    "    For each stage, provide:\n",
    "\n",
    "    A brief description of what is covered.\n",
    "    The key subtopics or skills within that stage.\n",
    "    Any prerequisites (if applicable).\n",
    "    The estimated time or effort needed for completion.\n",
    "    Recommended learning methods (e.g., hands-on projects, reading, exercises).\n",
    "    Ensure the curriculum flows logically from beginner to advanced levels, gradually increasing in difficulty. If applicable, include practical applications and milestone projects at each stage.\n",
    "\n",
    "    Output the curriculum as a structured, numbered list, with each stage labeled and well-defined. Format it clearly for easy reference.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = (f\"\"\"I want to build a curriculum builder that takes in a task or skill and outputs the subtopics and skills necessary to achieve the input. build me a prompt that does this\n",
    "            Here is the original prompt: {original_prompt}\n",
    "            Here are the two clarifying questions with their answers:\n",
    "            1: {answer1}\n",
    "            2: {answer2}\n",
    "            3: {answer3}\n",
    "            Now return only the refined prompt\n",
    "            \"\"\")\n",
    "\n",
    "    generated_prompt= model.invoke([sys_msg, AIMessage(content=prompt)])\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=generated_prompt.content)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################\n",
    "# Build the StateGraph\n",
    "#############################################\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"generate_questions\", generate_questions)\n",
    "builder.add_node(\"human_feedback_answers\", human_feedback_answers)\n",
    "builder.add_node(\"create_prompt\", create_prompt)\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, \"generate_questions\")\n",
    "builder.add_edge(\"generate_questions\", \"human_feedback_answers\")\n",
    "builder.add_edge(\"human_feedback_answers\", \"create_prompt\")\n",
    "builder.add_edge(\"create_prompt\", END)\n",
    "\n",
    "# Create a memory saver/checkpointer if needed\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile(\n",
    "    interrupt_before=[\"human_feedback_answers\"], \n",
    "    checkpointer=memory\n",
    ")\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "the user wants to learn about CNNs\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "the user wants to learn about CNNs\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Question 1 related to the user wants to learn about CNNs: What specific aspect of CNNs are you interested in learning about (e.g., architecture, applications, training process)?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Question 2 related to the user wants to learn about CNNs: Do you have any prior knowledge or experience with neural networks or machine learning concepts?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Question 3 related to the user wants to learn about CNNs: Are you looking for information on CNNs in a particular industry or field, such as healthcare, finance, or image processing?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Certainly! Here's the refined prompt based on the information provided:\n",
      "\n",
      "---\n",
      "\n",
      "I want to create a structured curriculum for learning about Convolutional Neural Networks (CNNs) with a focus on their architecture, specifically for image processing applications. The curriculum should be designed for someone who already has prior knowledge and experience with neural networks and machine learning concepts.\n",
      "\n",
      "Break the learning process into logical stages, each containing essential subtopics, concepts, or skills that must be mastered. For each stage, provide:\n",
      "\n",
      "1. A brief description of what is covered.\n",
      "2. The key subtopics or skills within that stage.\n",
      "3. Any prerequisites (if applicable).\n",
      "4. The estimated time or effort needed for completion.\n",
      "5. Recommended learning methods (e.g., hands-on projects, reading, exercises).\n",
      "\n",
      "Ensure the curriculum flows logically from beginner to advanced levels, gradually increasing in difficulty. Include practical applications and milestone projects at each stage, specifically related to image processing.\n",
      "\n",
      "Output the curriculum as a structured, numbered list, with each stage labeled and well-defined. Format it clearly for easy reference.\n",
      "\n",
      "=== Done! ===\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# MAIN INTERACTION LOGIC\n",
    "#############################################\n",
    "\n",
    "# 1. Ask for the topic\n",
    "user_input = input(\"What topic do you want to learn about: \")\n",
    "initial_input = {\n",
    "    \"messages\": [HumanMessage(content=f\"the user wants to learn about {user_input}\")]\n",
    "}\n",
    "\n",
    "# 2. Stream and get TWO AI questions, collecting the answers\n",
    "answers = []\n",
    "question_count = 0\n",
    "\n",
    "# First streaming pass: generate_questions node will run\n",
    "for event in graph.stream(initial_input, {\"configurable\": {\"thread_id\": \"15\"}}, stream_mode=\"values\"):\n",
    "    for new_event in event[\"messages\"]:\n",
    "        if \"Question\" in new_event.content:\n",
    "            new_event.pretty_print()  # Display the question\n",
    "            user_answer = input(\"Your answer: \")\n",
    "            answers.append(new_event.content + \":\\n\" + user_answer)\n",
    "            question_count += 1\n",
    "\n",
    "            # If we've already answered 2 questions, break out\n",
    "            if question_count >= 3:\n",
    "                break\n",
    "        else:\n",
    "            # Print any other messages from the AI\n",
    "            new_event.pretty_print()\n",
    "\n",
    "    if question_count >= 3:\n",
    "        break\n",
    "\n",
    "# 3. Update the graph with both answers at once, pointing to \"human_feedback_answers\"\n",
    "graph.update_state(\n",
    "    {\"configurable\": {\"thread_id\": \"15\"}},\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=a) for a in answers]\n",
    "    },\n",
    "    as_node=\"human_feedback_answers\"\n",
    ")\n",
    "\n",
    "# 4. Stream again to move from human_feedback_answers → create_prompt → END\n",
    "count = 0\n",
    "for event in graph.stream(None, {\"configurable\": {\"thread_id\": \"15\"}}, stream_mode=\"values\"):\n",
    "    #This helps us not return the human feedback\n",
    "    if count == 0 or count == 1:\n",
    "        count +=1\n",
    "        if count == 1:\n",
    "            continue\n",
    "\n",
    "    #for msg in event[\"messages\"]:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    final_prompt = event[\"messages\"][-1].content\n",
    "\n",
    "print(\"\\n=== Done! ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's the refined prompt based on the information provided:\n",
      "\n",
      "---\n",
      "\n",
      "I want to create a structured curriculum for learning about Convolutional Neural Networks (CNNs) with a focus on their architecture, specifically for image processing applications. The curriculum should be designed for someone who already has prior knowledge and experience with neural networks and machine learning concepts.\n",
      "\n",
      "Break the learning process into logical stages, each containing essential subtopics, concepts, or skills that must be mastered. For each stage, provide:\n",
      "\n",
      "1. A brief description of what is covered.\n",
      "2. The key subtopics or skills within that stage.\n",
      "3. Any prerequisites (if applicable).\n",
      "4. The estimated time or effort needed for completion.\n",
      "5. Recommended learning methods (e.g., hands-on projects, reading, exercises).\n",
      "\n",
      "Ensure the curriculum flows logically from beginner to advanced levels, gradually increasing in difficulty. Include practical applications and milestone projects at each stage, specifically related to image processing.\n",
      "\n",
      "Output the curriculum as a structured, numbered list, with each stage labeled and well-defined. Format it clearly for easy reference.\n"
     ]
    }
   ],
   "source": [
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_prompt = \"\"\"Please provide the content in the following format and structure exactly:\n",
    "\n",
    "### Stage {stage_number}: {stage_title}\n",
    "1. **Description**: {A concise description of this stage}\n",
    "2. **Key Subtopics/Skills**:\n",
    "   - {List each subtopic or skill as a new bullet item}\n",
    "   - {Bullet 2}\n",
    "   - {Bullet 3}\n",
    "3. **Prerequisites**: {List or describe prerequisite knowledge}\n",
    "4. **Estimated Time/Effort**: {e.g. \"1 week\", \"2 weeks\", etc.}\n",
    "5. **Recommended Methods**:\n",
    "   - {Bullet 1 for recommended method}\n",
    "   - {Bullet 2}\n",
    "   - {Bullet 3}\n",
    "\n",
    "Please create multiple stages using the same structure. End your content after the final stage without any additional text outside of this structure.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Stage 1: Introduction to Convolutional Neural Networks (CNNs)\n",
      "1. **Description**: This stage introduces the fundamental concepts of CNNs, focusing on their unique architecture and its application in image processing.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Understanding the basic architecture of CNNs\n",
      "   - Convolutional layers and how they work\n",
      "   - Pooling layers and their role in CNNs\n",
      "   - Activation functions (ReLU, etc.)\n",
      "3. **Prerequisites**: Basic knowledge of neural networks and machine learning principles.\n",
      "4. **Estimated Time/Effort**: 1 week\n",
      "5. **Recommended Methods**:\n",
      "   - Reading introductory materials on CNNs\n",
      "   - Watching tutorial videos\n",
      "   - Reviewing academic papers on CNN basics\n",
      "\n",
      "### Stage 2: Deep Dive into CNN Components\n",
      "1. **Description**: This stage delves deeper into the components of CNNs, exploring each part's functionality and significance.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Detailed exploration of convolutional filters\n",
      "   - Understanding backpropagation in CNNs\n",
      "   - Batch normalization and dropout techniques\n",
      "   - Advanced activation functions (Leaky ReLU, Sigmoid, Tanh)\n",
      "3. **Prerequisites**: Completion of Stage 1\n",
      "4. **Estimated Time/Effort**: 2 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Hands-on exercises with CNN components\n",
      "   - Implementing simple CNNs using frameworks like TensorFlow or PyTorch\n",
      "   - Analyzing case studies of CNNs in image processing\n",
      "\n",
      "### Stage 3: Building and Training CNNs\n",
      "1. **Description**: This stage focuses on the practical aspects of building and training CNNs for image processing tasks.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Designing CNN architectures for specific tasks\n",
      "   - Data preprocessing and augmentation techniques\n",
      "   - Training strategies and hyperparameter tuning\n",
      "   - Evaluating CNN performance with metrics\n",
      "3. **Prerequisites**: Completion of Stage 2\n",
      "4. **Estimated Time/Effort**: 3 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Developing and training CNN models with real datasets\n",
      "   - Participating in online coding challenges\n",
      "   - Conducting experiments to optimize CNN performance\n",
      "\n",
      "### Stage 4: Advanced CNN Architectures and Techniques\n",
      "1. **Description**: This stage covers advanced CNN architectures and cutting-edge techniques in the field of image processing.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Exploration of architectures like ResNet, VGG, and Inception\n",
      "   - Transfer learning and fine-tuning pretrained models\n",
      "   - Techniques for handling overfitting and improving generalization\n",
      "   - Analyzing recent advancements in CNN research\n",
      "3. **Prerequisites**: Completion of Stage 3\n",
      "4. **Estimated Time/Effort**: 3 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Implementation of advanced architectures on complex datasets\n",
      "   - Reading and summarizing recent research papers\n",
      "   - Engaging in group discussions and study groups\n",
      "\n",
      "### Stage 5: Practical Applications and Projects\n",
      "1. **Description**: This final stage emphasizes practical applications of CNNs in real-world image processing tasks, culminating in a comprehensive project.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Application of CNNs in various domains such as healthcare, automotive, and entertainment\n",
      "   - Developing end-to-end solutions for image classification, segmentation, and object detection\n",
      "   - Project management and collaboration in machine learning projects\n",
      "3. **Prerequisites**: Completion of Stage 4\n",
      "4. **Estimated Time/Effort**: 4 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Undertaking a capstone project related to CNNs in image processing\n",
      "   - Collaboration on open-source projects and contributions\n",
      "   - Presenting project findings and results in a formal settingNone"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = final_prompt + \": \" + structure_prompt\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages= [{ \"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        stream=True,  # <--- The key to getting partial tokens\n",
    "    )\n",
    "\n",
    "output = \"\"\n",
    "for chunk in response:\n",
    "    chunk_text = chunk.choices[0].delta.content\n",
    "    if chunk_text:\n",
    "        output += chunk_text\n",
    "    # Print the partial text without a newline, and flush for immediate display\n",
    "    print(chunk_text, end=\"\", flush=True)\n",
    "    #response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage Number: 1\n",
      "Stage Title: Introduction to Convolutional Neural Networks (CNNs)\n",
      "Description: This stage introduces the fundamental concepts of CNNs, focusing on their unique architecture and its application in image processing.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Understanding the basic architecture of CNNs\n",
      "   - Convolutional layers and how they work\n",
      "   - Pooling layers and their role in CNNs\n",
      "   - Activation functions (ReLU, etc.)\n",
      "3. **Prerequisites**: Basic knowledge of neural networks and machine learning principles.\n",
      "4. **Estimated Time/Effort**: 1 week\n",
      "5. **Recommended Methods**:\n",
      "   - Reading introductory materials on CNNs\n",
      "   - Watching tutorial videos\n",
      "   - Reviewing academic papers on CNN basics\n",
      "Subtopics: ['Understanding the basic architecture of CNNs', 'Convolutional layers and how they work', 'Pooling layers and their role in CNNs', 'Activation functions (ReLU, etc.)']\n",
      "Prerequisites: Basic knowledge of neural networks and machine learning principles.\n",
      "4. **Estimated Time/Effort**: 1 week\n",
      "5. **Recommended Methods**:\n",
      "   - Reading introductory materials on CNNs\n",
      "   - Watching tutorial videos\n",
      "   - Reviewing academic papers on CNN basics\n",
      "Time/Effort: 1 week\n",
      "5. **Recommended Methods**:\n",
      "   - Reading introductory materials on CNNs\n",
      "   - Watching tutorial videos\n",
      "   - Reviewing academic papers on CNN basics\n",
      "Methods: ['Reading introductory materials on CNNs']\n",
      "----\n",
      "Stage Number: 2\n",
      "Stage Title: Deep Dive into CNN Components\n",
      "Description: This stage delves deeper into the components of CNNs, exploring each part's functionality and significance.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Detailed exploration of convolutional filters\n",
      "   - Understanding backpropagation in CNNs\n",
      "   - Batch normalization and dropout techniques\n",
      "   - Advanced activation functions (Leaky ReLU, Sigmoid, Tanh)\n",
      "3. **Prerequisites**: Completion of Stage 1\n",
      "4. **Estimated Time/Effort**: 2 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Hands-on exercises with CNN components\n",
      "   - Implementing simple CNNs using frameworks like TensorFlow or PyTorch\n",
      "   - Analyzing case studies of CNNs in image processing\n",
      "Subtopics: ['Detailed exploration of convolutional filters', 'Understanding backpropagation in CNNs', 'Batch normalization and dropout techniques', 'Advanced activation functions (Leaky ReLU, Sigmoid, Tanh)']\n",
      "Prerequisites: Completion of Stage 1\n",
      "4. **Estimated Time/Effort**: 2 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Hands-on exercises with CNN components\n",
      "   - Implementing simple CNNs using frameworks like TensorFlow or PyTorch\n",
      "   - Analyzing case studies of CNNs in image processing\n",
      "Time/Effort: 2 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Hands-on exercises with CNN components\n",
      "   - Implementing simple CNNs using frameworks like TensorFlow or PyTorch\n",
      "   - Analyzing case studies of CNNs in image processing\n",
      "Methods: ['Hands-on exercises with CNN components']\n",
      "----\n",
      "Stage Number: 3\n",
      "Stage Title: Building and Training CNNs\n",
      "Description: This stage focuses on the practical aspects of building and training CNNs for image processing tasks.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Designing CNN architectures for specific tasks\n",
      "   - Data preprocessing and augmentation techniques\n",
      "   - Training strategies and hyperparameter tuning\n",
      "   - Evaluating CNN performance with metrics\n",
      "3. **Prerequisites**: Completion of Stage 2\n",
      "4. **Estimated Time/Effort**: 3 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Developing and training CNN models with real datasets\n",
      "   - Participating in online coding challenges\n",
      "   - Conducting experiments to optimize CNN performance\n",
      "Subtopics: ['Designing CNN architectures for specific tasks', 'Data preprocessing and augmentation techniques', 'Training strategies and hyperparameter tuning', 'Evaluating CNN performance with metrics']\n",
      "Prerequisites: Completion of Stage 2\n",
      "4. **Estimated Time/Effort**: 3 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Developing and training CNN models with real datasets\n",
      "   - Participating in online coding challenges\n",
      "   - Conducting experiments to optimize CNN performance\n",
      "Time/Effort: 3 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Developing and training CNN models with real datasets\n",
      "   - Participating in online coding challenges\n",
      "   - Conducting experiments to optimize CNN performance\n",
      "Methods: ['Developing and training CNN models with real datasets']\n",
      "----\n",
      "Stage Number: 4\n",
      "Stage Title: Advanced CNN Architectures and Techniques\n",
      "Description: This stage covers advanced CNN architectures and cutting-edge techniques in the field of image processing.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Exploration of architectures like ResNet, VGG, and Inception\n",
      "   - Transfer learning and fine-tuning pretrained models\n",
      "   - Techniques for handling overfitting and improving generalization\n",
      "   - Analyzing recent advancements in CNN research\n",
      "3. **Prerequisites**: Completion of Stage 3\n",
      "4. **Estimated Time/Effort**: 3 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Implementation of advanced architectures on complex datasets\n",
      "   - Reading and summarizing recent research papers\n",
      "   - Engaging in group discussions and study groups\n",
      "Subtopics: ['Exploration of architectures like ResNet, VGG, and Inception', 'Transfer learning and fine-tuning pretrained models', 'Techniques for handling overfitting and improving generalization', 'Analyzing recent advancements in CNN research']\n",
      "Prerequisites: Completion of Stage 3\n",
      "4. **Estimated Time/Effort**: 3 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Implementation of advanced architectures on complex datasets\n",
      "   - Reading and summarizing recent research papers\n",
      "   - Engaging in group discussions and study groups\n",
      "Time/Effort: 3 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Implementation of advanced architectures on complex datasets\n",
      "   - Reading and summarizing recent research papers\n",
      "   - Engaging in group discussions and study groups\n",
      "Methods: ['Implementation of advanced architectures on complex datasets']\n",
      "----\n",
      "Stage Number: 5\n",
      "Stage Title: Practical Applications and Projects\n",
      "Description: This final stage emphasizes practical applications of CNNs in real-world image processing tasks, culminating in a comprehensive project.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Application of CNNs in various domains such as healthcare, automotive, and entertainment\n",
      "   - Developing end-to-end solutions for image classification, segmentation, and object detection\n",
      "   - Project management and collaboration in machine learning projects\n",
      "3. **Prerequisites**: Completion of Stage 4\n",
      "4. **Estimated Time/Effort**: 4 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Undertaking a capstone project related to CNNs in image processing\n",
      "   - Collaboration on open-source projects and contributions\n",
      "   - Presenting project findings and results in a formal setting\n",
      "Subtopics: ['Application of CNNs in various domains such as healthcare, automotive, and entertainment', 'Developing end-to-end solutions for image classification, segmentation, and object detection', 'Project management and collaboration in machine learning projects']\n",
      "Prerequisites: Completion of Stage 4\n",
      "4. **Estimated Time/Effort**: 4 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Undertaking a capstone project related to CNNs in image processing\n",
      "   - Collaboration on open-source projects and contributions\n",
      "   - Presenting project findings and results in a formal setting\n",
      "Time/Effort: 4 weeks\n",
      "5. **Recommended Methods**:\n",
      "   - Undertaking a capstone project related to CNNs in image processing\n",
      "   - Collaboration on open-source projects and contributions\n",
      "   - Presenting project findings and results in a formal setting\n",
      "Methods: ['Undertaking a capstone project related to CNNs in image processing']\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_stages(text):\n",
    "    \"\"\"\n",
    "    Parses the LLM output text into a structured list of stages.\n",
    "    Each stage is a dictionary with keys:\n",
    "      stage_number, stage_title, description, key_subtopics, prerequisites,\n",
    "      time_effort, recommended_methods\n",
    "    \"\"\"\n",
    "    \n",
    "    # Regex to find each stage header: \"### Stage X: Title\"\n",
    "    stage_pattern = re.compile(r'^### Stage\\s+(\\d+):\\s+(.*)$', re.MULTILINE)\n",
    "\n",
    "    # Find all stages by their starting positions\n",
    "    matches = list(stage_pattern.finditer(text))\n",
    "\n",
    "    stages = []\n",
    "    \n",
    "    # We'll iterate over each match and slice the text from this stage to the next\n",
    "    for i, match in enumerate(matches):\n",
    "        stage_number = match.group(1).strip()\n",
    "        stage_title = match.group(2).strip()\n",
    "\n",
    "        # Start index for this stage's text\n",
    "        start_pos = match.end()\n",
    "        \n",
    "        # End index -> next stage start OR end of text\n",
    "        end_pos = matches[i+1].start() if i+1 < len(matches) else len(text)\n",
    "        \n",
    "        # Extract just this stage's block\n",
    "        stage_block = text[start_pos:end_pos].strip()\n",
    "        \n",
    "        # Now we parse out the parts 1,2,3,4,5 within stage_block\n",
    "        description = extract_section(stage_block, r'^1\\.\\s+\\*\\*Description\\*\\*:\\s*(.*)', single_line=True)\n",
    "        key_subtopics_block = extract_section(stage_block, r'^2\\.\\s+\\*\\*Key Subtopics/Skills\\*\\*:\\s*(.*?)(?=^3\\.|\\Z)', single_line=False)\n",
    "        prerequisites = extract_section(stage_block, r'^3\\.\\s+\\*\\*Prerequisites\\*\\*:\\s*(.*)', single_line=True)\n",
    "        time_effort = extract_section(stage_block, r'^4\\.\\s+\\*\\*Estimated Time/Effort\\*\\*:\\s*(.*)', single_line=True)\n",
    "        recommended_methods_block = extract_section(stage_block, r'^5\\.\\s+\\*\\*Recommended Methods\\*\\*:\\s*(.*?)(?=^###|$)', single_line=False)\n",
    "\n",
    "        # For Key Subtopics and Recommended Methods, we often have multiple lines\n",
    "        # Parse them as bullet points\n",
    "        key_subtopics = parse_bullet_points(key_subtopics_block)\n",
    "        recommended_methods = parse_bullet_points(recommended_methods_block)\n",
    "        \n",
    "        # Build dictionary\n",
    "        stage_data = {\n",
    "            \"stage_number\": stage_number,\n",
    "            \"stage_title\": stage_title,\n",
    "            \"description\": description,\n",
    "            \"key_subtopics\": key_subtopics,\n",
    "            \"prerequisites\": prerequisites,\n",
    "            \"time_effort\": time_effort,\n",
    "            \"recommended_methods\": recommended_methods\n",
    "        }\n",
    "\n",
    "        stages.append(stage_data)\n",
    "    \n",
    "    return stages\n",
    "\n",
    "def extract_section(text_block, pattern, single_line=True):\n",
    "    \"\"\"\n",
    "    Extracts the content for a particular section using a regex.\n",
    "      - If single_line=True, it extracts only the matching line.\n",
    "      - If single_line=False, it extracts multiple lines until a stop pattern.\n",
    "    \"\"\"\n",
    "    flags = re.MULTILINE | re.DOTALL\n",
    "    match = re.search(pattern, text_block, flags)\n",
    "    if match:\n",
    "        # If single_line, we just return the first capturing group directly\n",
    "        if single_line:\n",
    "            return match.group(1).strip()\n",
    "        else:\n",
    "            return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "def parse_bullet_points(text_block):\n",
    "    \"\"\"\n",
    "    Splits a section (like Key Subtopics or Recommended Methods) by bullet lines.\n",
    "    Assumes lines starting with '-' (or you can add other bullet chars).\n",
    "    \"\"\"\n",
    "    lines = text_block.splitlines()\n",
    "    bullets = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        # If the line starts with a dash, treat it as a bullet point\n",
    "        if line.startswith('-'):\n",
    "            # remove the dash and extra spaces\n",
    "            bullet_text = line[1:].strip()\n",
    "            if bullet_text:\n",
    "                bullets.append(bullet_text)\n",
    "    # Return list of bullet points\n",
    "    return bullets\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Example usage\n",
    "# -------------------\n",
    "\n",
    "parsed_stages = parse_stages(output)\n",
    "\n",
    "# Now you can see the structured data:\n",
    "for stage in parsed_stages:\n",
    "    print(f\"Stage Number: {stage['stage_number']}\")\n",
    "    print(f\"Stage Title: {stage['stage_title']}\")\n",
    "    print(f\"Description: {stage['description']}\")\n",
    "    print(f\"Subtopics: {stage['key_subtopics']}\")\n",
    "    print(f\"Prerequisites: {stage['prerequisites']}\")\n",
    "    print(f\"Time/Effort: {stage['time_effort']}\")\n",
    "    print(f\"Methods: {stage['recommended_methods']}\")\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage Number: Introduction to Convolutional Neural Networks (CNNs)\n",
      "Stage Number: Deep Dive into CNN Components\n",
      "Stage Number: Building and Training CNNs\n",
      "Stage Number: Advanced CNN Architectures and Techniques\n",
      "Stage Number: Practical Applications and Projects\n"
     ]
    }
   ],
   "source": [
    "for stage in parsed_stages:\n",
    "    print(f\"Stage Number: {stage['stage_title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Create a structured curriculum for learning about Convolutional Neural Networks (CNNs) with a focus on their architecture, specifically tailored for someone with prior knowledge of neural networks and machine learning concepts. The curriculum should be designed for application in image recognition. Break down the learning process into logical stages, each containing essential subtopics, concepts, or skills that must be mastered. For each stage, provide:\n",
    "\n",
    "1. A brief description of what is covered.\n",
    "2. The key subtopics or skills within that stage.\n",
    "3. Any prerequisites (if applicable).\n",
    "4. The estimated time or effort needed for completion.\n",
    "5. Recommended learning methods (e.g., hands-on projects, reading, exercises).\n",
    "\n",
    "Ensure the curriculum flows logically from beginner to advanced levels, gradually increasing in difficulty. Include practical applications and milestone projects at each stage related to image recognition. Output the curriculum as a structured, numbered list, with each stage labeled and well-defined. Format it clearly for easy reference.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# import re\n",
    "# import time\n",
    "\n",
    "\n",
    "structure_prompt = \"\"\"Please provide the content in the following format and structure exactly:\n",
    "\n",
    "### Stage {stage_number}: {stage_title}\n",
    "1. **Description**: {A concise description of this stage}\n",
    "2. **Key Subtopics/Skills**:\n",
    "   - {List each subtopic or skill as a new bullet item}\n",
    "        - **Objective:**\n",
    "        - **Resource**\n",
    "   - {Bullet 2}\n",
    "        - **Objective:**\n",
    "        - **Resource**\n",
    "   - {Bullet 3}\n",
    "        - **Objective:**\n",
    "        - **Resource**\n",
    "3. **Prerequisites**: {List or describe prerequisite knowledge}\n",
    "4. **Estimated Time/Effort**: {e.g. \"1 week\", \"2 weeks\", etc.}\n",
    "5. **Recommended Methods**:\n",
    "   - {Bullet 1 for recommended method}\n",
    "   - {Bullet 2}\n",
    "   - {Bullet 3}\n",
    "\n",
    "Please create multiple stages using the same structure. End your content after the final stage without any additional text outside of this structure.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# def create_roadmap(final_prompt):\n",
    "#     client = OpenAI()\n",
    "#     prompt = final_prompt + \": \" + structure_prompt\n",
    "\n",
    "#     response = client.chat.completions.create(\n",
    "#             model=\"gpt-4o\",\n",
    "#             messages= [{ \"role\": \"user\", \"content\": prompt}],\n",
    "#             temperature=0.7,\n",
    "#             stream=True,  # <--- The key to getting partial tokens\n",
    "#         )\n",
    "\n",
    "#     output = \"\"\n",
    "#     stage_text = \"\"\n",
    "#     for chunk in response:\n",
    "#         chunk_text = chunk.choices[0].delta.content\n",
    "#         if chunk_text:\n",
    "#             output += chunk_text\n",
    "#             with open(\"roadmap.md\", mode = \"a\") as md_file_append:\n",
    "#                 md_file_append.write(chunk_text)\n",
    "        \n",
    "\n",
    "#         # Print the partial text without a newline, and flush for immediate display\n",
    "#         print(chunk_text, end=\"\", flush=True)\n",
    "       \n",
    "#     return output\n",
    "\n",
    "\n",
    "import re\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "def fetch_resources_for_subtopics(subtopics):\n",
    "    \"\"\"Calls an LLM to fetch recommended resources for each subtopic.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    prompt = \"Provide useful learning resources open source articles or videos for the following subtopics:\\n\"\n",
    "    for subtopic in subtopics:\n",
    "        prompt += f\"- {subtopic}\\n\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def extract_subtopics(stage_text):\n",
    "    \"\"\"Extracts the Key Subtopics/Skills from a completed stage text.\"\"\"\n",
    "    match = re.search(r\"2\\.\\s\\*\\*Key Subtopics/Skills\\*\\*:\\n((?:\\s+- .+\\n)+)\", stage_text)\n",
    "    if match:\n",
    "        subtopics = [line.strip(\"- \").strip() for line in match.group(1).split(\"\\n\") if line.strip()]\n",
    "        return subtopics\n",
    "    return []\n",
    "\n",
    "async def create_roadmap(final_prompt):\n",
    "    \"\"\"Streams the roadmap, and once a stage is complete, fetches additional resources dynamically.\"\"\"\n",
    "    client = OpenAI()\n",
    "    prompt = final_prompt + \": \" + structure_prompt\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    output = \"\"\n",
    "    stage_text = \"\"  # Accumulate stage content\n",
    "    roadmap_file = \"roadmap.md\"\n",
    "    counter = 2\n",
    "    for chunk in response:\n",
    "        chunk_text = chunk.choices[0].delta.content\n",
    "        if chunk_text:\n",
    "            output += chunk_text\n",
    "            stage_text += chunk_text  # Append to the current stage\n",
    "\n",
    "            # Write the current text chunk to the file\n",
    "            with open(roadmap_file, mode=\"a\") as md_file_append:\n",
    "                md_file_append.write(chunk_text)\n",
    "\n",
    "            # Print streamed output\n",
    "            print(chunk_text, end=\"\", flush=True)\n",
    "\n",
    "            # Check if a stage is fully written\n",
    "            if \"**Prerequisites**\" in stage_text:\n",
    "                subtopics = extract_subtopics(stage_text)\n",
    "                \n",
    "                if subtopics:\n",
    "                    print(\"\\nFetching additional resources for subtopics...\\n\")\n",
    "                    \n",
    "                    resources = fetch_resources_for_subtopics(subtopics)\n",
    "                    \n",
    "                    with open(roadmap_file, mode=\"a\") as md_file_append:\n",
    "                        md_file_append.write(\"\\n#### Additional Resources\\n\" + resources + \"\\n\\n\")\n",
    "\n",
    "                    print(resources, \"\\n\")\n",
    "\n",
    "                stage_text = \"\"  # Reset stage text after processing\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Stage 1: Introduction to Convolutional Neural Networks (CNNs)\n",
      "1. **Description**: This stage introduces the foundational concepts of CNNs, focusing on their structure and basic operation within image recognition tasks.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Understanding the basic architecture of CNNs (convolutional layers, pooling layers, fully connected layers)\n",
      "   - The role of convolution in feature extraction\n",
      "   - Activation functions commonly used in CNNs\n",
      "3. **Prerequisites**\n",
      "Fetching additional resources for subtopics...\n",
      "\n",
      "Here are some open-source articles and videos that can help you understand these subtopics in Convolutional Neural Networks (CNNs):\n",
      "\n",
      "### Understanding the Basic Architecture of CNNs\n",
      "1. **Articles:**\n",
      "   - **\"A Beginner's Guide To Understanding Convolutional Neural Networks\"** by Adit Deshpande: This article provides a comprehensive overview of CNN architecture, explaining each component in detail. [Link to Article](https://adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks)\n",
      "   - **\"CS231n Convolutional Neural Networks for Visual Recognition\"**: This is a lecture note from Stanford's CS231n course, which provides an in-depth explanation of CNN architectures. [Link to Notes](http://cs231n.github.io/convolutional-networks/)\n",
      "\n",
      "2. **Videos:**\n",
      "   - **\"Convolutional Neural Networks - Deep Learning with Neural Networks and TensorFlow\"** by Sentdex: This is a part of a free YouTube series that explains CNNs in a clear and detailed manner. [Watch on YouTube](https://www.youtube.com/watch?v=FTr3n7uBIuE)\n",
      "   - **\"Deep Learning Specialization\"** by Andrew Ng on Coursera: While not completely free, you can access the video lectures for free by auditing the course. [Link to Course](https://www.coursera.org/specializations/deep-learning)\n",
      "\n",
      "### The Role of Convolution in Feature Extraction\n",
      "1. **Articles:**\n",
      "   - **\"The Matrix Calculus You Need For Deep Learning\"** by Terence Parr and Jeremy Howard: This paper explains the mathematics behind convolution in a digestible format. [Link to Paper](https://arxiv.org/abs/1802.01528)\n",
      "   - **\"Feature Extraction using Convolution\"** on Towards Data Science: This article explains how convolution helps in feature extraction and provides visualizations to aid understanding. [Link to Article](https://towardsdatascience.com/feature-extraction-using-convolution-308b6bda2d7)\n",
      "\n",
      "2. **Videos:**\n",
      "   - **\"Convolutional Neural Networks, a Visual and Interactive Guide\"** by R2RT: An interactive visual guide that explains the role of convolution in feature extraction. [Link to Interactive Guide](http://www.r2rt.com/implementing-a-cnn-for-text-classification-in-tensorflow.html)\n",
      "   - **\"Convolutional Neural Networks Explained\"** by Brandon Rohrer on YouTube: A concise explanation of convolutions and their role in feature extraction. [Watch on YouTube](https://www.youtube.com/watch?v=FmpDIaiMIeA)\n",
      "\n",
      "### Activation Functions Commonly Used in CNNs\n",
      "1. **Articles:**\n",
      "   - **\"Activation Functions in Neural Networks\"** by Sumit Saha on Towards Data Science: This article explains various activation functions, including those commonly used in CNNs. [Link to Article](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6)\n",
      "   - **\"A comprehensive guide to activation functions\"** by Satya Mallick on LearnOpenCV: Covers different activation functions and their use cases in CNNs. [Link to Article](https://www.learnopencv.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way/)\n",
      "\n",
      "2. **Videos:**\n",
      "   - **\"Activation Functions, Softmax, and the Learning Process\"** by 3Blue1Brown: A clear and intuitive explanation of activation functions, including those used in CNNs. [Watch on YouTube](https://www.youtube.com/watch?v=aircAruvnKk)\n",
      "   - **\"Neural Networks Activation Functions\"** by Deeplizard: This video covers various activation functions with practical examples. [Watch on YouTube](https://www.youtube.com/watch?v=-7scQpJT7uo)\n",
      "\n",
      "These resources should provide a good mix of theory and practical insights into CNNs and help you gain a deeper understanding of the architecture, feature extraction, and activation functions. \n",
      "\n",
      ": Basic knowledge of neural networks and machine learning concepts.\n",
      "4. **Estimated Time/Effort**: 1 week\n",
      "5. **Recommended Methods**:\n",
      "   - Reading introductory articles and textbooks\n",
      "   - Watching online lectures or tutorials\n",
      "   - Simple hands-on coding exercises using a library like TensorFlow or PyTorch\n",
      "\n",
      "### Stage 2: Deep Dive into Convolutional Operations\n",
      "1. **Description**: This stage explores the mathematical and functional aspects of convolutional operations in detail.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Understanding kernels and feature maps\n",
      "   - Stride, padding, and their effects on output dimensions\n",
      "   - Visualization of convolutional filters\n",
      "3. **Prerequisites**\n",
      "Fetching additional resources for subtopics...\n",
      "\n",
      "Below are some recommended open-source articles and videos for each of the subtopics you're interested in:\n",
      "\n",
      "### Understanding Kernels and Feature Maps\n",
      "\n",
      "1. **Articles:**\n",
      "   - [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/convolutional-networks/#conv) - A comprehensive guide from Stanford University that explains convolutions, kernels, and feature maps in detail.\n",
      "   - [Deep Learning Book - Chapter 9: Convolutional Networks](https://www.deeplearningbook.org/contents/convnets.html) - This book by Ian Goodfellow, Yoshua Bengio, and Aaron Courville is freely available online and provides a detailed theoretical foundation.\n",
      "\n",
      "2. **Videos:**\n",
      "   - [3Blue1Brown - But what is a Neural Network?](https://www.youtube.com/watch?v=aircAruvnKk) - While this video covers neural networks in general, it provides a good foundation for understanding how kernels and feature maps fit into the broader picture.\n",
      "   - [deeplearning.ai - Convolutional Neural Networks (Week 1)](https://www.coursera.org/learn/convolutional-neural-networks) - Andrew Ng's course is available for free on Coursera with auditing, covering the basics of CNNs including kernels and feature maps.\n",
      "\n",
      "### Stride, Padding, and Their Effects on Output Dimensions\n",
      "\n",
      "1. **Articles:**\n",
      "   - [A Beginner's Guide To Understanding Convolutional Neural Networks](https://towardsdatascience.com/a-beginners-guide-to-understanding-convolutional-neural-networks-using-tensorflow-step-by-step-7e0fd3c85f2c) - This article explains the concepts of stride and padding with visual aids and examples.\n",
      "   - [Convolution Arithmetic Tutorial](https://arxiv.org/abs/1603.07285) - A detailed paper that explains the mathematical foundations behind convolutions, strides, and padding.\n",
      "\n",
      "2. **Videos:**\n",
      "   - [deeplearning.ai - Convolutional Neural Networks (Week 2)](https://www.coursera.org/learn/convolutional-neural-networks) - This part of the course covers stride and padding, offering insights into how they affect the dimensions of the output.\n",
      "   - [StatQuest with Josh Starmer - Convolutional Neural Networks (CNN) Explained](https://www.youtube.com/watch?v=FmpDIaiMIeA) - A clear and concise explanation of CNNs, including the impact of stride and padding.\n",
      "\n",
      "### Visualization of Convolutional Filters\n",
      "\n",
      "1. **Articles:**\n",
      "   - [Feature Visualization: How neural networks build up their understanding of images](https://distill.pub/2017/feature-visualization/) - An in-depth article on how to visualize and interpret the features learned by convolutional filters.\n",
      "   - [Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901) - This research paper explores techniques for visualizing the features and filters learned by CNNs.\n",
      "\n",
      "2. **Videos:**\n",
      "   - [Udacity - Convolutional Neural Networks](https://www.udacity.com/course/convolutional-neural-networks--ud188) - This course includes sections on visualizing convolutional layers.\n",
      "   - [Two Minute Papers - Visualizing AI-Generated Images & Feature Maps](https://www.youtube.com/watch?v=AgkfIQ4IGaM) - A brief video introducing concepts for visualizing what CNNs learn.\n",
      "\n",
      "These resources should provide a solid foundation for understanding each of these subtopics in convolutional neural networks. \n",
      "\n",
      ": Completion of Stage 1\n",
      "4. **Estimated Time/Effort**: 1 week\n",
      "5. **Recommended Methods**:\n",
      "   - Detailed coding exercises to implement convolutions manually\n",
      "   - Visualization projects to understand filter operations\n",
      "   - Engaging with interactive simulations or visualizations\n",
      "\n",
      "### Stage 3: Pooling and Regularization Techniques\n",
      "1. **Description**: This stage focuses on enhancing CNNs by incorporating pooling layers and regularization techniques to improve model performance and prevent overfitting.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Max pooling and average pooling\n",
      "   - Dropout and batch normalization\n",
      "   - Data augmentation techniques\n",
      "3. **Prerequisites**\n",
      "Fetching additional resources for subtopics...\n",
      "\n",
      "Certainly! Here are some useful open-source resources, including articles and videos, for each of the subtopics you mentioned:\n",
      "\n",
      "### Max Pooling and Average Pooling\n",
      "\n",
      "1. **Articles:**\n",
      "   - **\"A Guide to Convolutional Neural Networks\"** by Sebastian Raschka: This comprehensive article covers CNN concepts, including pooling layers. It is available on GitHub.\n",
      "     - [GitHub Repository](https://github.com/rasbt/deeplearning-models)\n",
      "   - **\"Understanding Max Pooling and Average Pooling\"** on Medium: This article provides a clear explanation of pooling layers with visual aids.\n",
      "     - [Medium Article](https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-pooling-in-cnn-1f6e4f7c5b5)\n",
      "\n",
      "2. **Videos:**\n",
      "   - **\"Deep Learning: Convolutional Neural Networks\"** by Andrew Ng on Coursera: This course includes an excellent section on pooling layers, available for free.\n",
      "     - [Coursera Video](https://www.coursera.org/learn/convolutional-neural-networks)\n",
      "   - **\"Convolutional Neural Networks - Pooling Layers\"** on YouTube by StatQuest with Josh Starmer: A clear and engaging explanation of pooling concepts.\n",
      "     - [YouTube Video](https://www.youtube.com/watch?v=3q8p3Io_7YM)\n",
      "\n",
      "### Dropout and Batch Normalization\n",
      "\n",
      "1. **Articles:**\n",
      "   - **\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\"**: The original paper by Srivastava et al., available on arXiv, is a foundational resource.\n",
      "     - [arXiv Paper](https://arxiv.org/abs/1207.0580)\n",
      "   - **\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\"**: The original paper by Ioffe and Szegedy, also available on arXiv.\n",
      "     - [arXiv Paper](https://arxiv.org/abs/1502.03167)\n",
      "   - **\"Understanding Dropout in Neural Networks\"** on Towards Data Science: A practical guide to dropout usage.\n",
      "     - [Medium Article](https://towardsdatascience.com/understanding-dropout-in-neural-networks-7e7b697fa7c0)\n",
      "\n",
      "2. **Videos:**\n",
      "   - **\"Regularization: Dropout\"** by Andrew Ng on Coursera: Part of his deep learning specialization, explaining dropout.\n",
      "     - [Coursera Video](https://www.coursera.org/learn/deep-neural-networks)\n",
      "   - **\"Batch Normalization Explained\"** on YouTube by Deeplizard: Offers a detailed explanation of batch normalization.\n",
      "     - [YouTube Video](https://www.youtube.com/watch?v=H2r77aX5m6c)\n",
      "\n",
      "### Data Augmentation Techniques\n",
      "\n",
      "1. **Articles:**\n",
      "   - **\"Data Augmentation in Deep Learning: A Brief Review\"**: A review paper discussing various data augmentation techniques, available on arXiv.\n",
      "     - [arXiv Paper](https://arxiv.org/abs/1802.05329)\n",
      "   - **\"Comprehensive Guide to Image Augmentation Techniques in Deep Learning\"** on Analytics Vidhya: Discusses various image augmentation methods with examples.\n",
      "     - [Analytics Vidhya Article](https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/)\n",
      "\n",
      "2. **Videos:**\n",
      "   - **\"Data Augmentation for Deep Learning\"** on YouTube by deeplizard: A practical guide to data augmentation techniques.\n",
      "     - [YouTube Video](https://www.youtube.com/watch?v=r_It_X7v-1E)\n",
      "   - **\"Image Data Augmentation in Keras\"** on YouTube by Python Engineer: Demonstrates image augmentation using Keras.\n",
      "     - [YouTube Video](https://www.youtube.com/watch?v=JwSS70SZdyM)\n",
      "\n",
      "These resources should provide a solid foundation on each of these topics, with both theoretical insights and practical implementations. \n",
      "\n",
      ": Completion of Stage 2\n",
      "4. **Estimated Time/Effort**: 1 week\n",
      "5. **Recommended Methods**:\n",
      "   - Implementing pooling techniques in existing CNN models\n",
      "   - Experimenting with different regularization strategies\n",
      "   - Reading research papers or articles on advanced regularization techniques\n",
      "\n",
      "### Stage 4: Architectures and Transfer Learning\n",
      "1. **Description**: This stage introduces various CNN architectures and the concept of transfer learning for practical application in image recognition.\n",
      "2. **Key Subtopics/Skills**:\n",
      "   - Understanding and implementing popular CNN architectures (e.g., LeNet, AlexNet, VGG, ResNet)\n",
      "   - Transfer learning and fine-tuning pre-trained models\n",
      "   - Practical applications of transfer learning in image recognition\n",
      "3. **Prerequisites**\n",
      "Fetching additional resources for subtopics...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[369], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_roadmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[368], line 116\u001b[0m, in \u001b[0;36mcreate_roadmap\u001b[0;34m(final_prompt)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subtopics:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFetching additional resources for subtopics...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m     resources \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_resources_for_subtopics\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubtopics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(roadmap_file, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m md_file_append:\n\u001b[1;32m    119\u001b[0m         md_file_append\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m#### Additional Resources\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m resources \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[368], line 64\u001b[0m, in \u001b[0;36mfetch_resources_for_subtopics\u001b[0;34m(subtopics)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subtopic \u001b[38;5;129;01min\u001b[39;00m subtopics:\n\u001b[1;32m     62\u001b[0m     prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubtopic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 64\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/openai/resources/chat/completions.py:863\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    860\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    861\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/openai/_base_client.py:996\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    993\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 996\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1002\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Documents/Athena/RoadmapExperiments/TestVenv/lib/python3.9/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "create_roadmap(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TestVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
